{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70830724-2094-4216-9cce-6b17579593ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d53d44e-6c84-4e46-95fb-b4c0f497b7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_match=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad7f34b-97ec-4603-aeec-282e8335c367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b00e16d2-ad31-4588-b3a6-366cc3fa53f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import utils.envsetup\n",
    "from data.pmc_iterable import PMCIterable\n",
    "from data.topic_iterable import TopicIterable\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.doc_abstract_to_sentence_list_transform import DocAbstractToSentenceListTransform\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "if single_match:\n",
    "    from utils.ex_aspire_consent import AspireConSent, prepare_abstracts\n",
    "else:\n",
    "    from utils.ex_aspire_consent_multimatch import AspireConSent, AllPairMaskedWasserstein\n",
    "    from utils.ex_aspire_consent_multimatch import prepare_abstracts\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# topics = [x['ID'] for x in TopicIterable(format='aspire', topic_file_name='data/data_old_format/topics.pkl')]\n",
    "# topics.sort()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52cf52b4-6c3a-4cfe-beb9-b746b0766f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if single_match:\n",
    "    huggingface_model_name = 'allenai/aspire-contextualsentence-singlem-biomed' # single match\n",
    "else:\n",
    "    huggingface_model_name = 'allenai/aspire-contextualsentence-multim-biomed'  # multi match\n",
    "    ot_distance = AllPairMaskedWasserstein({}, device)\n",
    "aspire_tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name, cache_dir=\"/cs/labs/tomhope/taltatal/cache\")\n",
    "aspire_mv_model = AspireConSent(huggingface_model_name, device).to(device)\n",
    "# Empty dict of hyper params will force class to use defaults.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b3c496-afe3-4af0-81b9-25864d0c7a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_model(docs, tokenizer, model, device=torch.device(\"cpu\")):\n",
    "    bert_batch, abs_lens, sent_token_idxs = prepare_abstracts(batch_abs=docs,\n",
    "                                                              pt_lm_tokenizer=tokenizer)\n",
    "    # move batch to device, bert_batch is a dict\n",
    "    for k, v in bert_batch.items():\n",
    "        bert_batch[k] = v.to(device) if type(v) == torch.Tensor else v\n",
    "    # abs_lens is a list\n",
    "    abs_lens = torch.tensor(abs_lens, dtype=torch.long, device=device)\n",
    "\n",
    "    clsreps, contextual_sent_reps = model.forward(bert_batch=bert_batch,\n",
    "                                                  abs_lens=abs_lens,\n",
    "                                                  sent_tok_idxs=sent_token_idxs)\n",
    "    return abs_lens, contextual_sent_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf7b1489-697c-477c-87d3-18c076a3e3f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_to_same_size_along_axis(tensor_list, axis=0):\n",
    "    max_size = max([x.shape[axis] for x in tensor_list])\n",
    "    padded_list = []\n",
    "    for tensor in tensor_list:\n",
    "        if tensor.shape[axis] < max_size:\n",
    "            pad_size = max_size - tensor.shape[axis]\n",
    "            padded_list.append(F.pad(input=tensor, pad=(0, 0, 0, pad_size, 0, 0), mode='constant', value=0))\n",
    "        else:\n",
    "            padded_list.append(tensor)\n",
    "    return padded_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67de0a75-6698-450e-a254-617f906bc8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pmc_ids = pickle.load(open('data/data_old_format/pmc_ids.pkl', 'rb'))\n",
    "\n",
    "topics_dataloader = DataLoader(TopicIterable(format='aspire', topic_file_name='data/data_old_format/topics.pkl',\n",
    "                                             transform=DocAbstractToSentenceListTransform()), batch_size=1,\n",
    "                               collate_fn=lambda x: x)\n",
    "\n",
    "topics_dataloader = sorted([x for x in topics_dataloader], key=lambda x: int(x[0]['ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7474fbee-a1d3-4843-8698-eaa1bc836c3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Aspire Pre-Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "599ef2cb-65d3-4569-a61d-7123b545c1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 28.33it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_embeddings = []\n",
    "topic_abs_lens = []\n",
    "for topic_batch in tqdm.tqdm(topics_dataloader):\n",
    "    # move topic_batch to device, but avoid non tensors. its a list of dicts\n",
    "    topic_batch = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in x.items()} for x in topic_batch]\n",
    "\n",
    "    abs_lens, topic_embedding = apply_model(topic_batch, aspire_tokenizer, aspire_mv_model)\n",
    "    \n",
    "    topic_embeddings.append(topic_embedding)\n",
    "    topic_abs_lens.append(abs_lens)\n",
    "topic_embeddings = pad_to_same_size_along_axis(topic_embeddings, axis=1)\n",
    "topic_embeddings_tensor = torch.cat(topic_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84eb1ef3-273d-40a0-9833-7d904ab2de4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 28349/37707 [6:51:08<2:15:42,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "rankings = {x[0]['ID']: list() for x in topics_dataloader}\n",
    "for article_batch in tqdm.tqdm(DataLoader(PMCIterable(labeled_ids_or_filename=pmc_ids, format='aspire',\n",
    "                                                      transform=DocAbstractToSentenceListTransform()), batch_size=1,\n",
    "                                          collate_fn=lambda x: x)):\n",
    "    with torch.no_grad():\n",
    "        if len(article_batch[0]['ABSTRACT']) == 0:\n",
    "            continue\n",
    "        article_abs_lens, article_embedding = apply_model(article_batch, aspire_tokenizer, aspire_mv_model)\n",
    "        query_embeds = article_embedding\n",
    "        \n",
    "        if single_match:\n",
    "            for topic_abs_len, topic_embedding, i in zip(topic_abs_lens, topic_embeddings, range(len(topic_abs_lens))):\n",
    "                distance_matrix = torch.squeeze(torch.cdist(topic_embedding, query_embeds, p=2.0), 0)\n",
    "                argmax = torch.argmin(distance_matrix)\n",
    "                indices = torch.stack([argmax // distance_matrix.shape[1], argmax % distance_matrix.shape[1]], -1)\n",
    "                rankings[topics_dataloader[i][0]['ID']].append((article_batch[0]['ID'], distance_matrix[indices[0], indices[1]].to('cpu').numpy()))\n",
    "            \n",
    "        else:\n",
    "            for topic_abs_len, topic_embedding, i in zip(topic_abs_lens, topic_embeddings, range(len(topic_abs_lens))):\n",
    "                cand_embeds = topic_embedding\n",
    "                rep_len_tup = namedtuple('RepLen', ['embed', 'abs_lens'])\n",
    "                qt = rep_len_tup(embed=query_embeds.permute(0, 2, 1), abs_lens=[article_abs_lens[0]])\n",
    "                ct = rep_len_tup(embed=cand_embeds.permute(0, 2, 1), abs_lens=[topic_abs_len[0]])\n",
    "                wd, intermediate_items = ot_distance.compute_distance(query=qt, cand=ct, return_pair_sims=True)\n",
    "                rankings[topics_dataloader[i][0]['ID']].append((article_batch[0]['ID'], -1*(wd.to('cpu').detach().numpy().item())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c94a7a1b-b515-4423-9069-4a5ad02e5a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 26.48it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for k in tqdm.tqdm(rankings.keys()):\n",
    "    # rankings[k] = [(_id, rank.to('cpu').numpy().item()) for _id, rank in rankings[k]]\n",
    "    rankings[k].sort(key=lambda x: x[1])\n",
    "    pickle.dump(rankings[k], open('data/data_new_format/aspire_only/{}.pkl'.format(k), 'wb'))\n",
    "\n",
    "    # transport_plan = intermediate_items[3].data.numpy()[0, :article_abs_lens[0], :topic_abs_lens[0]]\n",
    "    # print(transport_plan.shape)\n",
    "    # # Print the sentences and plot the optimal transport plan for the pair of abstracts.\n",
    "    # print('\\n'.join([f'{i}: {s}' for i, s in enumerate(topics_dataloader[0][0]['ABSTRACT'])]))\n",
    "    # print('')\n",
    "    # print('\\n'.join([f'{i}: {s}' for i, s in enumerate(article_batch[0]['ABSTRACT'])]))\n",
    "    # h = sns.heatmap(transport_plan, linewidths=.7, cmap='Blues')\n",
    "    # h.set(xlabel='Candidate', ylabel='Query')\n",
    "    # h.tick_params(labelsize=5)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3c2cf-7402-47bf-b909-b38608f1faf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40103a09-0d5a-4120-8961-6ce15169189c",
   "metadata": {},
   "source": [
    "# ReRanker and Aspire Pre-Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896a939f-8a79-442c-bbc1-bbd31dfbcf95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "folder_path = \"data/data_old_format/reranker_out/\"\n",
    "\n",
    "reranker_rankings_dict = {}\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".pkl\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        base_name = os.path.splitext(file_name)[0]\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "            reranker_rankings_dict[base_name] = data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4560e06a-a6a4-4c1b-85ac-15a3284072db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_ids_per_topic = {topic_id:[article_id for article_id,rank in rankings] for topic_id,rankings in reranker_rankings_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6215ad95-0f33-47cb-9a0e-699356da2ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 19.81it/s]\n"
     ]
    }
   ],
   "source": [
    "topic_embeddings = []\n",
    "topic_abs_lens = []\n",
    "for topic_batch in tqdm.tqdm(topics_dataloader):\n",
    "    # move topic_batch to device, but avoid non tensors. its a list of dicts\n",
    "    topic_batch = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in x.items()} for x in topic_batch]\n",
    "\n",
    "    abs_lens, topic_embedding = apply_model(topic_batch, aspire_tokenizer, aspire_mv_model)\n",
    "    \n",
    "    topic_embeddings.append(topic_embedding)\n",
    "    topic_abs_lens.append(abs_lens)\n",
    "topic_embeddings = pad_to_same_size_along_axis(topic_embeddings, axis=1)\n",
    "topic_embeddings_tensor = torch.cat(topic_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3940669c-7ba5-4f81-9340-b1272549fc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:46<00:00, 21.41it/s]\n",
      "100%|██████████| 1000/1000 [00:51<00:00, 19.55it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.23it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.73it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.54it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 20.93it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 20.95it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.45it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.05it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.60it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.03it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.64it/s]\n",
      "100%|██████████| 1000/1000 [00:51<00:00, 19.33it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.18it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.06it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.56it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.07it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.05it/s]\n",
      "100%|██████████| 1000/1000 [00:50<00:00, 19.74it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 21.07it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 20.91it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 21.16it/s]\n",
      "100%|██████████| 1000/1000 [00:47<00:00, 20.95it/s]\n",
      "100%|██████████| 1000/1000 [00:46<00:00, 21.35it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.24it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.34it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.68it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.15it/s]\n",
      "100%|██████████| 1000/1000 [00:49<00:00, 20.31it/s]\n",
      "100%|██████████| 1000/1000 [00:48<00:00, 20.73it/s]\n"
     ]
    }
   ],
   "source": [
    "rankings = {x[0]['ID']: list() for x in topics_dataloader}\n",
    "for i in range(len(topic_embeddings)):\n",
    "    for article_batch in tqdm.tqdm(DataLoader(PMCIterable(labeled_ids_or_filename=article_ids_per_topic[topics_dataloader[i][0]['ID']], format='aspire',\n",
    "                                                          transform=DocAbstractToSentenceListTransform()), batch_size=1,\n",
    "                                              collate_fn=lambda x: x)):\n",
    "        with torch.no_grad():\n",
    "            if len(article_batch[0]['ABSTRACT']) == 0:\n",
    "                continue\n",
    "            article_abs_lens, article_embedding = apply_model(article_batch, aspire_tokenizer, aspire_mv_model)\n",
    "            query_embeds = article_embedding\n",
    "\n",
    "            if single_match:\n",
    "                distance_matrix = torch.squeeze(torch.cdist(topic_embeddings[i], query_embeds, p=2.0), 0)\n",
    "                argmax = torch.argmin(distance_matrix)\n",
    "                indices = torch.stack([argmax // distance_matrix.shape[1], argmax % distance_matrix.shape[1]], -1)\n",
    "                rankings[topics_dataloader[i][0]['ID']].append((article_batch[0]['ID'], distance_matrix[indices[0], indices[1]].to('cpu').numpy()))\n",
    "\n",
    "            else:\n",
    "                cand_embeds = topic_embeddings[i]\n",
    "                rep_len_tup = namedtuple('RepLen', ['embed', 'abs_lens'])\n",
    "                qt = rep_len_tup(embed=query_embeds.permute(0, 2, 1), abs_lens=[article_abs_lens[0]])\n",
    "                ct = rep_len_tup(embed=cand_embeds.permute(0, 2, 1), abs_lens=[topic_abs_lens[i][0]])\n",
    "                wd, intermediate_items = ot_distance.compute_distance(query=qt, cand=ct, return_pair_sims=True)\n",
    "                rankings[topics_dataloader[i][0]['ID']].append((article_batch[0]['ID'], -1*(wd.to('cpu').detach().numpy().item())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b41dac-4e6d-4259-8cc6-863eba8032a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:00<00:00, 101.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "folder_path = \"data/data_new_format/aspire_with_reranker/\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for k in tqdm.tqdm(rankings.keys()):\n",
    "    # rankings[k] = [(_id, rank.to('cpu').numpy().item()) for _id, rank in rankings[k]]\n",
    "    rankings[k].sort(key=lambda x: x[1])\n",
    "    pickle.dump(rankings[k], open(os.path.join(folder_path, '{}.pkl'.format(k)), 'wb'))\n",
    "\n",
    "    # transport_plan = intermediate_items[3].data.numpy()[0, :article_abs_lens[0], :topic_abs_lens[0]]\n",
    "    # print(transport_plan.shape)\n",
    "    # # Print the sentences and plot the optimal transport plan for the pair of abstracts.\n",
    "    # print('\\n'.join([f'{i}: {s}' for i, s in enumerate(topics_dataloader[0][0]['ABSTRACT'])]))\n",
    "    # print('')\n",
    "    # print('\\n'.join([f'{i}: {s}' for i, s in enumerate(article_batch[0]['ABSTRACT'])]))\n",
    "    # h = sns.heatmap(transport_plan, linewidths=.7, cmap='Blues')\n",
    "    # h.set(xlabel='Candidate', ylabel='Query')\n",
    "    # h.tick_params(labelsize=5)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b1874-b06b-475c-9ed0-22cdd70f5462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rankings['16']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
